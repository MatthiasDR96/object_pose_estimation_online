{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5_robot_target_callibration.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1-gDfRzBhXfVGFV_KXcV3D0An9r0uH3-f","authorship_tag":"ABX9TyOrzF2P3sZp0wp7HEDQ3nqW"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0CNwaWy8jBPG"},"source":["# Robot target kalibratie\n","\n","> Tot hiertoe kunnen we dus punten (objecten) gezien door de camera omzetten van camera coördinaten naar baselink coördinaten met de transformatiematrix ${}^{B}T_{C}$. Nu rest er ons enkel nog een object te detecteren met de camera. De camera kan namelijk RBG beelden uitlezen maar om effectief objecten te herkennen is er meer nodig. Eens we een object kunnen herkennen uit RGB beelden of uit pointclouds (3D beelden gebruik makende van dieptes die speciale dieptecamera's kunnen uitlezen), kunnen we de positie van dit object bepalen in camera frame en dit dan omzetten naar baselink frame. Het detecteren van objecten kan op verschillende manieren gebeuren. Maar hier gaan we er voorlopig vanuit dat een object beschreven is in een referentieframe dat we terug voorstellen met een dambordpatroon en dat we leggen in het robot veld.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JyLU3EwgWoHT"},"source":["# 1. Importeer bibliotheken\n","\n","Deze bibliotheken zijn nodig voor het volbrengen van dit script. In de CameraCalibration bibliotheek (die je vindt in de Classes folder op je Google Drive) vind je de code achter de commando's die je hier zal gebruiken.  "]},{"cell_type":"code","metadata":{"id":"SG-ckEA6drj3"},"source":["import sys\n","sys.path.append('/content/drive/My Drive/object_pose_estimation_online')\n","from Classes.CameraCalibration import *\n","from google.colab.patches import cv2_imshow"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_nVrH0rGWtSY"},"source":["# 2. Importeer alle beelden voor robot-target kalibratie\n","\n","> Alle afbeeldingen bevinden zich onder de map /content/drive/My Drive/object_pose_estimation_online/data/robot_target_calibration_images. Als je dit uitprint kan je zien dat dit een array is met alle 10 de padnamen naar elke afbeelding. "]},{"cell_type":"code","metadata":{"id":"ZjDrwABzWx6A"},"source":["# Find all image paths\n","robot_target_calibration_images_file = '/content/drive/My Drive/object_pose_estimation_online/data/robot_target_calibration_images/RTC_image_original_*.jpg'\n","images_path_names = get_image_path_names(robot_target_calibration_images_file)\n","print(images_path_names)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5vRK0UJ_k2gp"},"source":["> We kunnen terug kijken hoe een dergelijke afbeelding eruit ziet. Merk op dat het dambordpatroon deze keer in het robot veld ligt. Als we het object (doosje ernaast) voorlopig op een gekende plaats in dat frame leggen en we de positie van het target frame in het baselinkframe kunnen bepalen, dan kent de robot dus de positie van het object ten opzichte van zichzelf en kan het het object gaan grijpen. "]},{"cell_type":"code","metadata":{"id":"DoaYUIucWx8V"},"source":["# Preview image\n","image_path = images_path_names[0]\n","image = read_image(image_path)\n","cv2_imshow(image)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"He3dNPAJW7iO"},"source":["# 3. Load baselink-camera transformation matrix\n","\n","Hier laden we de baselink-camera matrix die we in vorig script berekend hebben. "]},{"cell_type":"code","metadata":{"id":"ZOD7cmZxKjnP"},"source":["# Import baselink-camera transformation matrix (numpy data)\n","mean_baselink_camera_transformation_file = '/content/drive/My Drive/object_pose_estimation_online/data/matrix_files/mean_baselink_camera_transformation.npy'\n","bc_transform = get_numpy_data(mean_baselink_camera_transformation_file)\n","print(\"Baselink-camera transform: \\n\\n\" + str(bc_transform))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oF0j77vxusF2"},"source":["> Deze matrix stelt dus de transformatiematrix voor van baselink frame {B} naar het cameraframe {C}, ${}^{B}T_{C}$. Of in andere woorden, deze matrix kan punten beschreven in het camera frame omzetten in het baselink frame. \n","\n","$$ {}^{B}P = {}^{B}T_{T}*{}^{T}P$$\n","\n","> Merk op dat de getallen in de laatste kolom van boven naar beneden de x-, y-, en z-positie weergeven van het camera frame ten opzichte van het baselink frame."]},{"cell_type":"markdown","metadata":{"id":"V-gRZZnlXJVg"},"source":["# 4. Laden van de berekende intrinsieke camera matrix\n","\n","> In vorige opgave heb je de intrinsieke matrix opgelsagen, deze werd automatisch opgeslagen onder /content/drive/My Drive/object_pose_estimation_online/data/matrix_files/intrinsic_camera_properties.npz. Deze kunnen we nu laden. De functie \"load_intrinsic_camera_matrix\" geeft je niet enkel de intrinsieke matrix, maar ook de distrotiecoëfficiënten nodig voor de kalibratie."]},{"cell_type":"code","metadata":{"id":"p92jHbJrKjk8"},"source":["# Load intrinsic camera matrix and distortion coefficients\n","intrinsic_camera_matrix_file = '/content/drive/My Drive/object_pose_estimation_online/data/matrix_files//intrinsic_camera_properties.npz'\n","mtx, dist = load_intrinsic_camera_matrix(intrinsic_camera_matrix_file)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KF-hy5LdXU7Y"},"source":["# 5. Robot-target calibration\n","\n","Hier gaan we dus nog eens een extrinsieke kalibratie uitvoeren om de positie van het target frame, gelegen in het robot veld, te kennen in het camera frame. Weer worden de metrische coördinaten van het dambordpatroon bekomen, een beeld ingelezen, omgezet naar grayscale, hoeken berekend, en deze info aan het kalibratiealgoritme gegeven. "]},{"cell_type":"code","metadata":{"id":"Zvx8aHsOKp3X"},"source":["# Prepare object points in 3D space in meters\n","objp = get_object_points()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IeIn-eUbXdMp"},"source":["# Read image\n","image = read_image(image_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Ke3pkJoXdPM"},"source":["# Turn image to grayscale\n","gray = image_to_grayscale(image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C9nbYQBRXdRo"},"source":["# Find the corners in the chessbord calibration tool\n","corners = find_corners(gray)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oo43fn-CXdUY"},"source":["# Get extrinsic camera calibration matrix (target - camera transform)\n","ct_transform = extrinsic_calibration(objp, corners, mtx, dist)\n","print(\"Camera-target transform: \\n\\n\" + str(ct_transform))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bXOH940rXjR3"},"source":["# Get baselink - target transform\n","bt_transform = multiply_transforms(bc_transform, ct_transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HMbTUbaAKtIY"},"source":["# Save the mean baselink - target transformation matrix\n","baselink_target_transformation_file = '/content/drive/My Drive/object_pose_estimation_online/data/matrix_files/mean_baselink_target_transformation'\n","save_to_numpy(baselink_target_transformation_file, bt_transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5f5CyDt5KtKr"},"source":["print(\"Baselink-camera transform: \\n\\n\" + str(bt_transform))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JDIOMB0uwPrc"},"source":["\n","\n","> Deze matrix geeft dus de positie van het targetframe in baselink frame. Als we in dit frame een object definiëren op een gekende positie in het target frame, kunnen we dit object dus kennen in het baselink frame en grijpen met de robot. \n","\n"]}]}